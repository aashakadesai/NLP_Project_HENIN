{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "517_Cyberbullying.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXzha8mZAS32"
      },
      "source": [
        "Baseline implementations:\r\n",
        "\r\n",
        "RNN, GRU, random forest, and a logistic regression \r\n",
        "\r\n",
        "Github link: [HENIN](https://github.com/HsinYu7330/HENIN)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNmEhtUQA0N3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d13d665-e40b-442c-a441-33c1496e218e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive')\r\n",
        "!ls /gdrive"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "MyDrive  Shareddrives\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y15kH4ewICyY",
        "outputId": "0af2147f-9365-4c7f-b1c0-5e6a7a62c284"
      },
      "source": [
        "import os\r\n",
        "BASE_PATH = '/gdrive/My Drive/colab_files/'\r\n",
        "DATA_PATH = '/gdrive/My Drive/colab_files/nlp_project_files/'\r\n",
        "\r\n",
        "#UNCOMMENT FOLLOWING SECTION TO UNTAR DATASETS\r\n",
        "#MODIFY FILE NAMES AS NEEDED\r\n",
        "\r\n",
        "if not os.path.exists(DATA_PATH):\r\n",
        "  print('here')\r\n",
        "  os.makedirs(DATA_PATH)\r\n",
        "  #print(os.getcwd())\r\n",
        "\r\n",
        "  os.chdir(BASE_PATH)\r\n",
        "  !ls\r\n",
        "  !tar -zxf nlp_project.tar.gz -C nlp_project_files\r\n",
        "  print('Extracted all files')\r\n",
        "\r\n",
        "\r\n",
        "#!ls -1 | wc -l\r\n",
        "os.chdir(DATA_PATH)\r\n",
        "!ls"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  HENIN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPKkjFW5Jxv8",
        "outputId": "a2cc4d08-00c9-41e8-c9a7-df0cc7d8a45e"
      },
      "source": [
        "DATA_PATH = '/gdrive/My Drive/colab_files/nlp_project_files/data'\r\n",
        "CODE_PATH = '/gdrive/My Drive/colab_files/nlp_project_files/HENIN'\r\n",
        "PREPROCESSED_DATA = '/gdrive/My Drive/colab_files/nlp_project_files/HENIN/preprocessData'\r\n",
        "os.chdir(CODE_PATH)\r\n",
        "\r\n",
        "!ls\r\n",
        "\r\n",
        "if not os.path.exists(PREPROCESSED_DATA):\r\n",
        "  os.makedirs('preprocessData')\r\n",
        "\r\n",
        "!python3 preprocessing.py\r\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images\t   preprocessData    __pycache__  train.py\n",
            "layers.py  preprocessing.py  README.md\t  utils.py\n",
            "Traceback (most recent call last):\n",
            "  File \"preprocessing.py\", line 9, in <module>\n",
            "    from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/__init__.py\", line 5, in <module>\n",
            "    from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/parsing/__init__.py\", line 4, in <module>\n",
            "    from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/parsing/preprocessing.py\", line 40, in <module>\n",
            "    from gensim import utils\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/utils.py\", line 40, in <module>\n",
            "    import scipy.sparse\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/sparse/__init__.py\", line 229, in <module>\n",
            "    from .base import *\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\", line 7, in <module>\n",
            "    from scipy._lib._numpy_compat import broadcast_to\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/_lib/_numpy_compat.py\", line 16, in <module>\n",
            "    _assert_warns = np.testing.assert_warns\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/__init__.py\", line 208, in __getattr__\n",
            "    import numpy.testing as testing\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/testing/__init__.py\", line 8, in <module>\n",
            "    from unittest import TestCase\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 963, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 906, in _find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1280, in find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1252, in _get_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1364, in find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 81, in _path_stat\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLkoGPsJQaKx"
      },
      "source": [
        "import pickle\r\n",
        "os.chdir(PREPROCESSED_DATA)\r\n",
        "# load preprocessed data\r\n",
        "with open('Dat4ModelUNLAB.pickle', 'rb') as f:\r\n",
        "    Dat4Model = pickle.load(f)\r\n",
        "    \r\n",
        "# load multi-hot user vectors of each session\r\n",
        "with open('multi_hot_usersVINE_THIRD.pickle', 'rb') as f:\r\n",
        "    multi_hot_users = pickle.load(f)  \r\n",
        "    \r\n",
        "w2v_vec_all = Dat4Model['w2v_vec_all'] # features for HENIN\r\n",
        "x_lr = Dat4Model['textFeat_clf_all'] # LR features\r\n",
        "y_all = Dat4Model['y_all'] # target for HENIN\r\n",
        "textFeat_all = Dat4Model['textFeat_all']"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py_0uyRxx8Ov",
        "outputId": "aa3731bb-a2f9-4a28-d1f2-cc42393fcc19"
      },
      "source": [
        "import numpy as np\r\n",
        "from sklearn.model_selection import cross_validate\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, roc_auc_score, precision_score, f1_score\r\n",
        "\r\n",
        "acc = 0\r\n",
        "prec = 0\r\n",
        "rec = 0\r\n",
        "f1 = 0\r\n",
        "\r\n",
        "for i in range(5):\r\n",
        "  clf = LogisticRegression(class_weight=\"balanced\", max_iter=1000)\r\n",
        "  scoring = {'accuracy': 'accuracy',\r\n",
        "            'recall': 'recall',\r\n",
        "            'precision': 'precision',\r\n",
        "            'roc_auc': 'roc_auc',\r\n",
        "            'f1': 'f1'}\r\n",
        "  cross_val_scores = cross_validate(clf, x_lr, y_all, cv=5, scoring=scoring)\r\n",
        "  acc += np.mean(cross_val_scores['test_accuracy'])\r\n",
        "  prec += np.mean(cross_val_scores['test_precision'])\r\n",
        "  rec += np.mean(cross_val_scores['test_recall'])\r\n",
        "  f1 += np.mean(cross_val_scores['test_f1'])\r\n",
        "  print('mean test accuracy: ', np.mean(cross_val_scores['test_accuracy']))\r\n",
        "  print('mean test percision: ', np.mean(cross_val_scores['test_precision']))\r\n",
        "  print('mean test recall: ', np.mean(cross_val_scores['test_recall']))\r\n",
        "  print('mean test f1: ', np.mean(cross_val_scores['test_f1']))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean test accuracy:  0.5990486257928118\n",
            "mean test percision:  0.32183908045977005\n",
            "mean test recall:  0.8\n",
            "mean test f1:  0.4529550002326772\n",
            "mean test accuracy:  0.5990486257928118\n",
            "mean test percision:  0.32183908045977005\n",
            "mean test recall:  0.8\n",
            "mean test f1:  0.4529550002326772\n",
            "mean test accuracy:  0.5990486257928118\n",
            "mean test percision:  0.32183908045977005\n",
            "mean test recall:  0.8\n",
            "mean test f1:  0.4529550002326772\n",
            "mean test accuracy:  0.5990486257928118\n",
            "mean test percision:  0.32183908045977005\n",
            "mean test recall:  0.8\n",
            "mean test f1:  0.4529550002326772\n",
            "mean test accuracy:  0.5990486257928118\n",
            "mean test percision:  0.32183908045977005\n",
            "mean test recall:  0.8\n",
            "mean test f1:  0.4529550002326772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcwx7Wamx-Ul",
        "outputId": "d4b6191a-32dc-4ccf-b588-bf5a465b2aba"
      },
      "source": [
        "print('total mean test accuracy: ', str(acc/5))\r\n",
        "print('total mean test percision: ', str(prec/5))\r\n",
        "print('total mean test recall: ', str(rec/5))\r\n",
        "print('total mean test f1: ', str(f1/5))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total mean test accuracy:  0.5990486257928118\n",
            "total mean test percision:  0.32183908045977005\n",
            "total mean test recall:  0.8\n",
            "total mean test f1:  0.4529550002326772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7HmsbaZz0Ln",
        "outputId": "7e6af06a-fa03-4ca6-d7e8-096c97cb5089"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "\r\n",
        "acc = 0\r\n",
        "prec = 0\r\n",
        "rec = 0\r\n",
        "f1 = 0\r\n",
        "\r\n",
        "for i in range(5):\r\n",
        "  clf = RandomForestClassifier(max_depth=2, random_state=0)\r\n",
        "  scoring = {'accuracy': 'accuracy',\r\n",
        "            'recall': 'recall',\r\n",
        "            'precision': 'precision',\r\n",
        "            'roc_auc': 'roc_auc',\r\n",
        "            'f1': 'f1'}\r\n",
        "  cross_val_scores = cross_validate(clf, x_lr, y_all, cv=5, scoring=scoring)\r\n",
        "  acc += np.mean(cross_val_scores['test_accuracy'])\r\n",
        "  prec += np.mean(cross_val_scores['test_precision'])\r\n",
        "  rec += np.mean(cross_val_scores['test_recall'])\r\n",
        "  f1 += np.mean(cross_val_scores['test_f1'])\r\n",
        "  print('mean test accuracy: ', np.mean(cross_val_scores['test_accuracy']))\r\n",
        "  print('mean test percision: ', np.mean(cross_val_scores['test_precision']))\r\n",
        "  print('mean test recall: ', np.mean(cross_val_scores['test_recall']))\r\n",
        "  print('mean test f1: ', np.mean(cross_val_scores['test_f1']))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mean test accuracy:  0.7832980972515856\n",
            "mean test percision:  0.1\n",
            "mean test recall:  0.04444444444444444\n",
            "mean test f1:  0.06153846153846153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mean test accuracy:  0.7832980972515856\n",
            "mean test percision:  0.1\n",
            "mean test recall:  0.04444444444444444\n",
            "mean test f1:  0.06153846153846153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mean test accuracy:  0.7832980972515856\n",
            "mean test percision:  0.1\n",
            "mean test recall:  0.04444444444444444\n",
            "mean test f1:  0.06153846153846153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mean test accuracy:  0.7832980972515856\n",
            "mean test percision:  0.1\n",
            "mean test recall:  0.04444444444444444\n",
            "mean test f1:  0.06153846153846153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mean test accuracy:  0.7832980972515856\n",
            "mean test percision:  0.1\n",
            "mean test recall:  0.04444444444444444\n",
            "mean test f1:  0.06153846153846153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V40z3LRD0CBa",
        "outputId": "12e79fa6-8b40-466f-fc56-ef050484ffd4"
      },
      "source": [
        "print('total mean test accuracy: ', str(acc/5))\r\n",
        "print('total mean test percision: ', str(prec/5))\r\n",
        "print('total mean test recall: ', str(rec/5))\r\n",
        "print('total mean test f1: ', str(f1/5))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total mean test accuracy:  0.7832980972515856\n",
            "total mean test percision:  0.1\n",
            "total mean test recall:  0.04444444444444444\n",
            "total mean test f1:  0.06153846153846153\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}